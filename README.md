Olá, pessoal, boa noite!

Na aula de hoje foi passado um trabalho de pesquisa - Apache Spark com Delta Lake e Apache Iceberg - como tema da aula de arquitetura de dados.

TEMA DO TRABALHO: APACHE SPARK COM DELTA LAKE E APACHE ICEBERG

Grupos de no máximo 3 alunos.
Criar um repositório/projeto público no GitHub, adicionar os participante como membros e encaminhar por e-mail para jorge.silva@satc.edu.br com o link do repo e o nome de todos os participantes até as 23:59h do dia 25/09.
Criar um ambiente PySpark e Jupyter Labs, implementando Delta Lake e Apache Iceberg.
Descrever o passo a passo para reproduzir o seu ambiente no arquivo README (instruções bem detalhadas, bibliotecas, versões, etc). Faça uso dos recursos de markdown – copy code, formatação, links, etc.
Podem utilizar como fonte de pesquisa os vídeos do canal do youtube DataWay BR.
Projetos do github: github.com/jlsilva01/spark-delta e github.com/jlsilva01/spark-iceberg
Utilizem o padrão de projetos Python descrito em aula (Python para Engenharia de Dados - material de apoio.pdf)
Escolham apenas um gerenciador de projetos/pacote python e o utilizem em todo o seu projeto. POETRY ou UV.
Descreva o cenário da(s) tabela(s) em um arquivo tipo notebook – modelo ER da tabela, imagens e códigos DDL - e da fonte de dados utilizada (preferência dados públicos) e evidencie e explique, com exemplos, os comandos de INSERT, UPDATE e DELETE nas tabelas Delta e Iceberg dentro do Apache Spark através do MKDOCS (1 página para Iceberg, 1 página para Delta).
